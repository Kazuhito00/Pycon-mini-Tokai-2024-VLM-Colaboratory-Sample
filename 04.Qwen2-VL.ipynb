{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# モデル選択"
      ],
      "metadata": {
        "id": "WtAyYZNt3tkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
        "# model_path = \"Qwen/Qwen2-VL-7B-Instruct\""
      ],
      "metadata": {
        "id": "kPvmGU7g3tbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# パッケージインストール"
      ],
      "metadata": {
        "id": "b1080w89dojB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q av\n",
        "!pip install -q ffmpeg\n",
        "!pip install -q qwen_vl_utils\n",
        "!pip install -q git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "Ak6vHwomIX0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデルロード"
      ],
      "metadata": {
        "id": "pBqvcMtYd_k9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZfNKvLwTEFQ"
      },
      "outputs": [],
      "source": [
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
        "\n",
        "qwen2_vl_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "qwen2_vl_processor = AutoProcessor.from_pretrained(\n",
        "    model_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "# 推論用関数\n",
        "def run_inference(processor, model, messages):\n",
        "    # 入力プロンプトの準備\n",
        "    text_prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "    inputs = processor(\n",
        "        text=[text_prompt],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    # 推論\n",
        "    output_ids = model.generate(**inputs, max_new_tokens=128)\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids) :]\n",
        "        for input_ids, output_ids in zip(inputs.input_ids, output_ids)\n",
        "    ]\n",
        "\n",
        "    # デコード\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "    )\n",
        "\n",
        "    return output_text"
      ],
      "metadata": {
        "id": "LJ0zL7VdDz7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 画像推論サンプル"
      ],
      "metadata": {
        "id": "90jtiZWOcY3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### サンプル画像ダウンロード"
      ],
      "metadata": {
        "id": "pDAuFLKBi_Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Kazuhito00/Qwen2-VL-Colaboratory-Sample/main/sample.jpg -q -O test.jpg"
      ],
      "metadata": {
        "id": "tMhbT8l1Uih3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "cv_image = cv2.imread('test.jpg')\n",
        "rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
        "pil_image = Image.fromarray(rgb_image)\n",
        "\n",
        "print(pil_image.size)\n",
        "pil_image"
      ],
      "metadata": {
        "id": "8hWhwrTYjCJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# ローカルファイル指定での推論\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": \"test.jpg\"},\n",
        "            {\"type\": \"text\", \"text\": \"画像を説明してください\"},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "output_text = run_inference(qwen2_vl_processor, qwen2_vl_model, messages)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "bnNv7tJFd9Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# PILイメージ指定での推論\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": pil_image},\n",
        "            {\"type\": \"text\", \"text\": \"画像を説明してください\"},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "output_text = run_inference(qwen2_vl_processor, qwen2_vl_model, messages)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "T4qmDFT8TMz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# PILイメージ指定での推論(サイズ変更)\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": pil_image, \"resized_width\": 300, \"resized_height\": 200},\n",
        "            {\"type\": \"text\", \"text\": \"画像を説明してください\"},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "output_text = run_inference(qwen2_vl_processor, qwen2_vl_model, messages)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "hnrENKHiHv7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# URL指定での推論\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": \"https://raw.githubusercontent.com/Kazuhito00/Qwen2-VL-Colaboratory-Sample/main/sample.jpg\"},\n",
        "            {\"type\": \"text\", \"text\": \"画像を説明してください\"},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "output_text = run_inference(qwen2_vl_processor, qwen2_vl_model, messages)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "nFSFKaSpFXvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import base64\n",
        "\n",
        "_, imencode_image = cv2.imencode('.jpg', cv_image)\n",
        "base64_image = base64.b64encode(imencode_image)\n",
        "\n",
        "# メッセージの準備\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": \"data:image/jpg;base64,\" + base64_image.decode(\"ascii\")},\n",
        "            {\"type\": \"text\", \"text\": \"画像を説明してください\"},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "output_text = run_inference(qwen2_vl_processor, qwen2_vl_model, messages)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "gV3OJKVzFnE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 動画推論"
      ],
      "metadata": {
        "id": "mHB9lhIVFFkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### サンプル動画ダウンロード"
      ],
      "metadata": {
        "id": "B6lAEtuuN609"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Kazuhito00/Qwen2-VL-Colaboratory-Sample/main/sample.mp4 -q -O test.mp4"
      ],
      "metadata": {
        "id": "whR3Qf3f5xS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 冒頭4秒のみの動画を生成\n",
        "!ffmpeg -loglevel quiet -i test.mp4 -t 4 -c copy test_4s.mp4"
      ],
      "metadata": {
        "id": "mHWnkdOQIq6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# ローカルファイル指定での推論\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"video\", \"video\": \"test_4s.mp4\", \"fps\": 1.0},  # メモリが不足するためFPSを制限、必要に応じて画像と同様に幅、高さも指定可能\n",
        "            {\"type\": \"text\", \"text\": \"動画を説明してください\"},\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "output_text = run_inference(qwen2_vl_processor, qwen2_vl_model, messages)\n",
        "print(output_text)"
      ],
      "metadata": {
        "id": "m_KS_SoXI7fC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}